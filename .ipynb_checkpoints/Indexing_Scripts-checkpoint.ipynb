{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_primary_shards': 15,\n",
       " 'active_shards': 15,\n",
       " 'active_shards_percent_as_number': 100.0,\n",
       " 'cluster_name': 'smartpub',\n",
       " 'delayed_unassigned_shards': 0,\n",
       " 'initializing_shards': 0,\n",
       " 'number_of_data_nodes': 1,\n",
       " 'number_of_in_flight_fetch': 0,\n",
       " 'number_of_nodes': 1,\n",
       " 'number_of_pending_tasks': 0,\n",
       " 'relocating_shards': 0,\n",
       " 'status': 'green',\n",
       " 'task_max_waiting_in_queue_millis': 0,\n",
       " 'timed_out': False,\n",
       " 'unassigned_shards': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.cluster.health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_nodes': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'cluster_name': 'smartpub',\n",
       " 'nodes': {'ebADX0twTlqxi_hYrNewow': {'adaptive_selection': {'ebADX0twTlqxi_hYrNewow': {'avg_queue_size': 0,\n",
       "     'avg_response_time_ns': 120065,\n",
       "     'avg_service_time_ns': 64326,\n",
       "     'outgoing_searches': 0,\n",
       "     'rank': '0.1'}},\n",
       "   'breakers': {'accounting': {'estimated_size': '1.8mb',\n",
       "     'estimated_size_in_bytes': 1888034,\n",
       "     'limit_size': '990.7mb',\n",
       "     'limit_size_in_bytes': 1038876672,\n",
       "     'overhead': 1.0,\n",
       "     'tripped': 0},\n",
       "    'fielddata': {'estimated_size': '0b',\n",
       "     'estimated_size_in_bytes': 0,\n",
       "     'limit_size': '594.4mb',\n",
       "     'limit_size_in_bytes': 623326003,\n",
       "     'overhead': 1.03,\n",
       "     'tripped': 0},\n",
       "    'in_flight_requests': {'estimated_size': '78.8kb',\n",
       "     'estimated_size_in_bytes': 80692,\n",
       "     'limit_size': '990.7mb',\n",
       "     'limit_size_in_bytes': 1038876672,\n",
       "     'overhead': 1.0,\n",
       "     'tripped': 0},\n",
       "    'parent': {'estimated_size': '1.8mb',\n",
       "     'estimated_size_in_bytes': 1968726,\n",
       "     'limit_size': '693.5mb',\n",
       "     'limit_size_in_bytes': 727213670,\n",
       "     'overhead': 1.0,\n",
       "     'tripped': 0},\n",
       "    'request': {'estimated_size': '0b',\n",
       "     'estimated_size_in_bytes': 0,\n",
       "     'limit_size': '594.4mb',\n",
       "     'limit_size_in_bytes': 623326003,\n",
       "     'overhead': 1.0,\n",
       "     'tripped': 0}},\n",
       "   'discovery': {'cluster_state_queue': {'committed': 0,\n",
       "     'pending': 0,\n",
       "     'total': 0},\n",
       "    'published_cluster_states': {'compatible_diffs': 0,\n",
       "     'full_states': 0,\n",
       "     'incompatible_diffs': 0}},\n",
       "   'fs': {'data': [{'available_in_bytes': 220183314432,\n",
       "      'free_in_bytes': 220183314432,\n",
       "      'mount': '/data2 (/dev/vdb)',\n",
       "      'path': '/data2/SmartPub/elasticsearch/data/nodes/0',\n",
       "      'total_in_bytes': 268304384000,\n",
       "      'type': 'xfs'}],\n",
       "    'io_stats': {'devices': [{'device_name': 'vdb',\n",
       "       'operations': 532779,\n",
       "       'read_kilobytes': 0,\n",
       "       'read_operations': 0,\n",
       "       'write_kilobytes': 30606888,\n",
       "       'write_operations': 532779}],\n",
       "     'total': {'operations': 532779,\n",
       "      'read_kilobytes': 0,\n",
       "      'read_operations': 0,\n",
       "      'write_kilobytes': 30606888,\n",
       "      'write_operations': 532779}},\n",
       "    'least_usage_estimate': {'available_in_bytes': 220183355392,\n",
       "     'path': '/data2/SmartPub/elasticsearch/data/nodes/0',\n",
       "     'total_in_bytes': 268304384000,\n",
       "     'used_disk_percent': 17.935237542745483},\n",
       "    'most_usage_estimate': {'available_in_bytes': 220183355392,\n",
       "     'path': '/data2/SmartPub/elasticsearch/data/nodes/0',\n",
       "     'total_in_bytes': 268304384000,\n",
       "     'used_disk_percent': 17.935237542745483},\n",
       "    'timestamp': 1522150033932,\n",
       "    'total': {'available_in_bytes': 220183314432,\n",
       "     'free_in_bytes': 220183314432,\n",
       "     'total_in_bytes': 268304384000}},\n",
       "   'host': '127.0.0.1',\n",
       "   'http': {'current_open': 3, 'total_opened': 123},\n",
       "   'indices': {'completion': {'size_in_bytes': 0},\n",
       "    'docs': {'count': 1380237, 'deleted': 2632},\n",
       "    'fielddata': {'evictions': 0, 'memory_size_in_bytes': 0},\n",
       "    'flush': {'total': 90, 'total_time_in_millis': 10388},\n",
       "    'get': {'current': 0,\n",
       "     'exists_time_in_millis': 0,\n",
       "     'exists_total': 0,\n",
       "     'missing_time_in_millis': 0,\n",
       "     'missing_total': 0,\n",
       "     'time_in_millis': 0,\n",
       "     'total': 0},\n",
       "    'indexing': {'delete_current': 0,\n",
       "     'delete_time_in_millis': 0,\n",
       "     'delete_total': 0,\n",
       "     'index_current': 0,\n",
       "     'index_failed': 0,\n",
       "     'index_time_in_millis': 398746,\n",
       "     'index_total': 3595594,\n",
       "     'is_throttled': False,\n",
       "     'noop_update_total': 0,\n",
       "     'throttle_time_in_millis': 0},\n",
       "    'merges': {'current': 0,\n",
       "     'current_docs': 0,\n",
       "     'current_size_in_bytes': 0,\n",
       "     'total': 1092,\n",
       "     'total_auto_throttle_in_bytes': 1020845060,\n",
       "     'total_docs': 12867314,\n",
       "     'total_size_in_bytes': 7389122662,\n",
       "     'total_stopped_time_in_millis': 0,\n",
       "     'total_throttled_time_in_millis': 47705,\n",
       "     'total_time_in_millis': 233532},\n",
       "    'query_cache': {'cache_count': 0,\n",
       "     'cache_size': 0,\n",
       "     'evictions': 0,\n",
       "     'hit_count': 0,\n",
       "     'memory_size_in_bytes': 0,\n",
       "     'miss_count': 0,\n",
       "     'total_count': 0},\n",
       "    'recovery': {'current_as_source': 0,\n",
       "     'current_as_target': 0,\n",
       "     'throttle_time_in_millis': 0},\n",
       "    'refresh': {'listeners': 0,\n",
       "     'total': 11189,\n",
       "     'total_time_in_millis': 147307},\n",
       "    'request_cache': {'evictions': 0,\n",
       "     'hit_count': 0,\n",
       "     'memory_size_in_bytes': 0,\n",
       "     'miss_count': 0},\n",
       "    'search': {'fetch_current': 0,\n",
       "     'fetch_time_in_millis': 3023,\n",
       "     'fetch_total': 36925,\n",
       "     'open_contexts': 0,\n",
       "     'query_current': 0,\n",
       "     'query_time_in_millis': 5685,\n",
       "     'query_total': 290830,\n",
       "     'scroll_current': 0,\n",
       "     'scroll_time_in_millis': 0,\n",
       "     'scroll_total': 0,\n",
       "     'suggest_current': 0,\n",
       "     'suggest_time_in_millis': 0,\n",
       "     'suggest_total': 0},\n",
       "    'segments': {'count': 90,\n",
       "     'doc_values_memory_in_bytes': 6360,\n",
       "     'file_sizes': {},\n",
       "     'fixed_bit_set_memory_in_bytes': 0,\n",
       "     'index_writer_memory_in_bytes': 0,\n",
       "     'max_unsafe_auto_id_timestamp': -1,\n",
       "     'memory_in_bytes': 1888034,\n",
       "     'norms_memory_in_bytes': 15104,\n",
       "     'points_memory_in_bytes': 6911,\n",
       "     'stored_fields_memory_in_bytes': 182272,\n",
       "     'term_vectors_memory_in_bytes': 0,\n",
       "     'terms_memory_in_bytes': 1677387,\n",
       "     'version_map_memory_in_bytes': 0},\n",
       "    'store': {'size_in_bytes': 1050335879},\n",
       "    'translog': {'operations': 1403693,\n",
       "     'size_in_bytes': 1042254645,\n",
       "     'uncommitted_operations': 1348537,\n",
       "     'uncommitted_size_in_bytes': 675687275},\n",
       "    'warmer': {'current': 0, 'total': 4442, 'total_time_in_millis': 30}},\n",
       "   'ingest': {'pipelines': {},\n",
       "    'total': {'count': 0, 'current': 0, 'failed': 0, 'time_in_millis': 0}},\n",
       "   'ip': '127.0.0.1:9300',\n",
       "   'jvm': {'buffer_pools': {'direct': {'count': 41,\n",
       "      'total_capacity_in_bytes': 134882521,\n",
       "      'used_in_bytes': 134882522},\n",
       "     'mapped': {'count': 246,\n",
       "      'total_capacity_in_bytes': 1033497227,\n",
       "      'used_in_bytes': 1033497227}},\n",
       "    'classes': {'current_loaded_count': 11373,\n",
       "     'total_loaded_count': 11451,\n",
       "     'total_unloaded_count': 78},\n",
       "    'gc': {'collectors': {'old': {'collection_count': 4,\n",
       "       'collection_time_in_millis': 155},\n",
       "      'young': {'collection_count': 870, 'collection_time_in_millis': 5484}}},\n",
       "    'mem': {'heap_committed_in_bytes': 1038876672,\n",
       "     'heap_max_in_bytes': 1038876672,\n",
       "     'heap_used_in_bytes': 341412616,\n",
       "     'heap_used_percent': 32,\n",
       "     'non_heap_committed_in_bytes': 117493760,\n",
       "     'non_heap_used_in_bytes': 110545256,\n",
       "     'pools': {'old': {'max_in_bytes': 724828160,\n",
       "       'peak_max_in_bytes': 724828160,\n",
       "       'peak_used_in_bytes': 549015224,\n",
       "       'used_in_bytes': 210644688},\n",
       "      'survivor': {'max_in_bytes': 34865152,\n",
       "       'peak_max_in_bytes': 34865152,\n",
       "       'peak_used_in_bytes': 34865152,\n",
       "       'used_in_bytes': 2921632},\n",
       "      'young': {'max_in_bytes': 279183360,\n",
       "       'peak_max_in_bytes': 279183360,\n",
       "       'peak_used_in_bytes': 279183360,\n",
       "       'used_in_bytes': 127846296}}},\n",
       "    'threads': {'count': 52, 'peak_count': 57},\n",
       "    'timestamp': 1522150033932,\n",
       "    'uptime_in_millis': 679869926},\n",
       "   'name': 'ebADX0t',\n",
       "   'os': {'cgroup': {'cpu': {'cfs_period_micros': 100000,\n",
       "      'cfs_quota_micros': -1,\n",
       "      'control_group': '/system.slice/elasticsearch.service',\n",
       "      'stat': {'number_of_elapsed_periods': 0,\n",
       "       'number_of_times_throttled': 0,\n",
       "       'time_throttled_nanos': 0}},\n",
       "     'cpuacct': {'control_group': '/system.slice/elasticsearch.service',\n",
       "      'usage_nanos': 1844817450940},\n",
       "     'memory': {'control_group': '/system.slice/elasticsearch.service',\n",
       "      'limit_in_bytes': '9223372036854771712',\n",
       "      'usage_in_bytes': '3602161664'}},\n",
       "    'cpu': {'load_average': {'15m': 1.63, '1m': 2.03, '5m': 2.05},\n",
       "     'percent': 0},\n",
       "    'mem': {'free_in_bytes': 24493150208,\n",
       "     'free_percent': 36,\n",
       "     'total_in_bytes': 67560984576,\n",
       "     'used_in_bytes': 43067834368,\n",
       "     'used_percent': 64},\n",
       "    'swap': {'free_in_bytes': 534769664,\n",
       "     'total_in_bytes': 534769664,\n",
       "     'used_in_bytes': 0},\n",
       "    'timestamp': 1522150033932},\n",
       "   'process': {'cpu': {'percent': 0, 'total_in_millis': 1843420},\n",
       "    'max_file_descriptors': 65536,\n",
       "    'mem': {'total_virtual_in_bytes': 5916110848},\n",
       "    'open_file_descriptors': 237,\n",
       "    'timestamp': 1522150033932},\n",
       "   'roles': ['master', 'data', 'ingest'],\n",
       "   'script': {'cache_evictions': 0, 'compilations': 0},\n",
       "   'thread_pool': {'bulk': {'active': 1,\n",
       "     'completed': 124426,\n",
       "     'largest': 4,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 4},\n",
       "    'fetch_shard_started': {'active': 0,\n",
       "     'completed': 5,\n",
       "     'largest': 5,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 1},\n",
       "    'fetch_shard_store': {'active': 0,\n",
       "     'completed': 0,\n",
       "     'largest': 0,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 0},\n",
       "    'flush': {'active': 0,\n",
       "     'completed': 219,\n",
       "     'largest': 2,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 2},\n",
       "    'force_merge': {'active': 0,\n",
       "     'completed': 0,\n",
       "     'largest': 0,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 0},\n",
       "    'generic': {'active': 0,\n",
       "     'completed': 108524,\n",
       "     'largest': 4,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 4},\n",
       "    'get': {'active': 0,\n",
       "     'completed': 0,\n",
       "     'largest': 0,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 0},\n",
       "    'index': {'active': 0,\n",
       "     'completed': 0,\n",
       "     'largest': 0,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 0},\n",
       "    'listener': {'active': 0,\n",
       "     'completed': 0,\n",
       "     'largest': 0,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 0},\n",
       "    'management': {'active': 1,\n",
       "     'completed': 90569,\n",
       "     'largest': 4,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 4},\n",
       "    'refresh': {'active': 0,\n",
       "     'completed': 1156331,\n",
       "     'largest': 2,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 2},\n",
       "    'search': {'active': 0,\n",
       "     'completed': 385931,\n",
       "     'largest': 7,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 7},\n",
       "    'snapshot': {'active': 0,\n",
       "     'completed': 0,\n",
       "     'largest': 0,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 0},\n",
       "    'warmer': {'active': 0,\n",
       "     'completed': 0,\n",
       "     'largest': 0,\n",
       "     'queue': 0,\n",
       "     'rejected': 0,\n",
       "     'threads': 0}},\n",
       "   'timestamp': 1522150033929,\n",
       "   'transport': {'rx_count': 0,\n",
       "    'rx_size_in_bytes': 0,\n",
       "    'server_open': 0,\n",
       "    'tx_count': 0,\n",
       "    'tx_size_in_bytes': 0},\n",
       "   'transport_address': '127.0.0.1:9300'}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.nodes.stats()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Command for ES replicas per node\n",
    "\n",
    "curl -XPUT 'localhost:9200/ir/_settings' -H 'Content-Type: application/json' -d '{\"number_of_replicas\": 0}'\n",
    "\n",
    "curl -XPUT 'localhost:9200/twosent/_settings' -H 'Content-Type: application/json' -d '{\"number_of_replicas\": 0}'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl -XPUT 'localhost:9200/_cluster/settings?pretty' -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "    \"persistent\":\n",
    "  { \"cluster.routing.allocation.enable\" : \"all\"\n",
    "  }\n",
    "}\n",
    "'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2 Full Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import nltk\n",
    "import config as cfg\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_primary_shards': 0,\n",
       " 'active_shards': 0,\n",
       " 'active_shards_percent_as_number': 100.0,\n",
       " 'cluster_name': 'smartpub',\n",
       " 'delayed_unassigned_shards': 0,\n",
       " 'initializing_shards': 0,\n",
       " 'number_of_data_nodes': 1,\n",
       " 'number_of_in_flight_fetch': 0,\n",
       " 'number_of_nodes': 1,\n",
       " 'number_of_pending_tasks': 0,\n",
       " 'relocating_shards': 0,\n",
       " 'status': 'green',\n",
       " 'task_max_waiting_in_queue_millis': 0,\n",
       " 'timed_out': False,\n",
       " 'unassigned_shards': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('localhost:' + str(cfg.mongoDB_Port))\n",
    "db = client.pub\n",
    "pub = client.pub.publications\n",
    "es = Elasticsearch(\n",
    "    [{'host': 'localhost', 'port': 9200}], timeout=30, max_retries=10, retry_on_timeout=True\n",
    ")\n",
    "es.cluster.health(wait_for_status='yellow', request_timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def return_chapters(mongo_string_search, db):\n",
    "    results = db.publications.find(mongo_string_search)\n",
    "    chapters = list()\n",
    "    chapter_nums = list()\n",
    "    list_of_docs = list()\n",
    "    merged_chapters = list()\n",
    "    \n",
    "    my_dict = {\n",
    "        \"_id\": \"\",\n",
    "        \"title\": \"\",\n",
    "        \"content\": \"\",\n",
    "        \"journal\": \"\",\n",
    "        \"year\":\"\"\n",
    "    }\n",
    "    for i, r in enumerate(results):\n",
    "        # try:\n",
    "        # list_of_sections = list()\n",
    "        my_dict['_id'] = r['_id']\n",
    "        my_dict['title'] = r['title']\n",
    "        try:\n",
    "            my_dict['journal'] = r['booktitle']\n",
    "        except: \n",
    "            pass\n",
    "        try:\n",
    "            my_dict['journal'] = r['journal']\n",
    "        except: \n",
    "            pass\n",
    "        try:\n",
    "            my_dict['year'] = r['year']\n",
    "        except: \n",
    "            pass\n",
    "        try:\n",
    "            my_dict['content'] = r['content']['fulltext']\n",
    "        except:\n",
    "            my_dict['content'] = \"\"\n",
    "            # print(my_dict)\n",
    "            # sys.exit(1)\n",
    "\n",
    "        list_of_docs.append(my_dict)\n",
    "\n",
    "        my_dict = {\n",
    "            \"_id\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"content\": \"\",\n",
    "            \"journal\": \"\",\n",
    "            \"year\": \"\"\n",
    "        }\n",
    "\n",
    "    return list_of_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filter_conference = [\"WWW\", \"ICSE\", \"VLDB\", \"JCDL\", \"TREC\",  \"SIGIR\", \"ICWSM\", \"ECDL\", \"ESWC\", \"TPDL\", \n",
    "                     'pbio', 'pgen', 'bmcgen', 'bmcbiot', 'bmcneur', 'bmceb', 'genbio', 'bcr']\n",
    "\n",
    "list_of_pubs = []\n",
    "\n",
    "for booktitle in filter_conference:\n",
    "    mongo_string_search = {'$or': [{'$and': [{'booktitle': booktitle}, {'content.fulltext': {'$exists': True}}]} ,\n",
    "                                   {'$and': [{'journal': booktitle},   {'content.fulltext': {'$exists': True}}]} ]}\n",
    "    list_of_pubs.append(return_chapters(mongo_string_search, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_pubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for pubs in list_of_pubs:\n",
    "    actions = []\n",
    "    \n",
    "    for cur in pubs:\n",
    "        text = cur[\"content\"]\n",
    "        \n",
    "        print(cur['_id'])\n",
    "        print(cur['journal'])\n",
    "\n",
    "        actions.append({\n",
    "                    \"_index\": \"ir\",\n",
    "                    \"_type\": \"publications\",\n",
    "                    \"_id\" : cur['_id'],\n",
    "                    \"journal\": cur['journal'],\n",
    "                    \"year\": cur['year'],\n",
    "                    \"_source\" : {\n",
    "                        \"text\" : text,\n",
    "                        \"title\": cur[\"title\"]\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    if len(actions) == 0:\n",
    "            continue\n",
    "\n",
    "    res = helpers.bulk(es, actions)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3 Twosent Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_primary_shards': 5,\n",
       " 'active_shards': 5,\n",
       " 'active_shards_percent_as_number': 100.0,\n",
       " 'cluster_name': 'smartpub',\n",
       " 'delayed_unassigned_shards': 0,\n",
       " 'initializing_shards': 0,\n",
       " 'number_of_data_nodes': 1,\n",
       " 'number_of_in_flight_fetch': 0,\n",
       " 'number_of_nodes': 1,\n",
       " 'number_of_pending_tasks': 0,\n",
       " 'relocating_shards': 0,\n",
       " 'status': 'green',\n",
       " 'task_max_waiting_in_queue_millis': 0,\n",
       " 'timed_out': False,\n",
       " 'unassigned_shards': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import math\n",
    "import requests\n",
    "import nltk\n",
    "import _pickle as cPickle\n",
    "import config as cfg\n",
    "import logging\n",
    "\n",
    "###############################\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "client = MongoClient('localhost:' + str(cfg.mongoDB_Port))\n",
    "pub = client.pub.publications\n",
    "db = client.pub\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}],\n",
    "                   timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "es.cluster.health(wait_for_status='yellow', request_timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def return_paragraphs(mongo_string_search, db):\n",
    "    # mongo_string_search = {\"dblpkey\": \"{}\".format(dblkey)}\n",
    "    results = db.publications.find(mongo_string_search)\n",
    "    chapters = list()\n",
    "    chapter_nums = list()\n",
    "    list_of_docs = list()\n",
    "    # list_of_abstracts = list()\n",
    "    merged_chapters = list()\n",
    "    \n",
    "    my_dict = {\n",
    "        \"_id\": \"\",\n",
    "        \"paragraphs\": list(),\n",
    "        \"title\": \"\"\n",
    "    }\n",
    "    \n",
    "    for i, r in enumerate(results):\n",
    "        # try:\n",
    "        # list_of_sections = list()\n",
    "        my_dict['_id'] = r['_id']\n",
    "        my_dict['title'] = r['title']\n",
    "        paragraphs = []\n",
    "        \n",
    "#         ########################################################\n",
    "        try:\n",
    "            for chapter in r['content']['chapters']:\n",
    "                if (chapter == {}):\n",
    "                    continue\n",
    "\n",
    "                    # remove the filter that removes related works\n",
    "                    # elif str(chapter['title']).lower() in filter_chapters:\n",
    "                    # print(chapter['title'])\n",
    "\n",
    "                # print(chapter['title'])\n",
    "                for paragraph in chapter['paragraphs']:\n",
    "                    if paragraph == {}:\n",
    "                        continue\n",
    "                    paragraphs.append(paragraph)\n",
    "\n",
    "            my_dict['paragraphs'] = paragraphs\n",
    "\n",
    "        except:\n",
    "            logging.exception('No chapters in ' + r['_id'], exc_info=True)\n",
    "            \n",
    "                \n",
    "#         try:\n",
    "#             for paragraph in r['content']['paragraphs']:\n",
    "#                 if paragraph == {}:\n",
    "#                     continue\n",
    "#                 paragraphs.append(paragraph['text'])\n",
    "#             my_dict['paragraphs'] = paragraphs\n",
    "        \n",
    "#         except:\n",
    "#             logging.exception('No paragraphs in ' + r['_id'], exc_info=True)\n",
    "#             continue\n",
    "#         ########################################################    \n",
    "\n",
    "        list_of_docs.append(my_dict)\n",
    "        my_dict = {\n",
    "            \"_id\": \"\",\n",
    "            \"paragraphs\": list(),\n",
    "            \"title\": \"\"\n",
    "        }\n",
    "\n",
    "    return list_of_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = db.publications.find(mongo_string_search)\n",
    "mongo_string_search = {'$or': [{'$and': [{'booktitle': publication}, {'content.fulltext': {'$exists': True}}]} ,\n",
    "                                   {'$and': [{'journal': publication},   {'content.fulltext': {'$exists': True}}]} ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_dict = {\n",
    "    \"_id\": \"\",\n",
    "    \"paragraphs\": list(),\n",
    "    \"title\": \"\"\n",
    "}\n",
    "for i, r in enumerate(results):\n",
    "    # try:\n",
    "    # list_of_sections = list()\n",
    "    my_dict['_id'] = r['_id']\n",
    "    my_dict['title'] = r['title']\n",
    "    paragraphs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eukaryotic cells utilize intricate mechanisms for the uptake and intracellular sorting of various macromolecules, such as membrane components and extracellular proteins. Microscopic imaging studies have helped considerably to describe and define important steps of the uptake process. It has been shown that the cytosolic face of the plasma membrane is studded with small, domed assemblages of peripheral membrane proteins. These constitute transitory sorting stations that dynamically remodel the composition of the cell surface in response to both intracellular and extracellular stimuli. Typically, within a minute of forming, these assemblages invaginate to generate “buds” that then detach, generating small (∼60 nm), membrane-bound transport vesicles that deliver their contents (often receptors) to specific intracellular compartments—namely acceptor early endosomes—for further dissemination within the cell (Figure 1). This invagination and sorting process is called endocytosis, and although several morphologically and structurally distinct endocytic sorting assemblies occur at the surface of most cells [1], perhaps the most recognizable are polyhedral clathrin-coated structures. First identified to be cargo-selective transport carriers during yolk uptake and storage within oocytes of blood-fed mosquitoes [2], clathrin-coated vesicles are now known to support many vital cellular processes, ranging from nutrient uptake, cellular locomotion, and transcriptional regulation and proliferation to complex developmental morphogenetic events. Clathrin-mediated endocytosis also seems important for the efficacy of anti-receptor monoclonal antibody-based tumor therapy [3] and for susceptibility to double-stranded RNA–mediated gene silencing [4].\n",
      "\n",
      "Schematic depiction of a deeply invaginated clathrin-coated bud and a flat clathrin-coated plaque undergoing endocytic uptake and the resultant uncoated vesicles. Both transmembrane cargo (green and blue receptors) that are selectively sorted into clathrin-coated vesicles and bulk membrane-associated cell surface proteins (orange and magenta) that are perhaps nonselectively incorporated into plaques are shown.\n",
      "\n",
      "Clathrin assembles at discrete patches on the plasma membrane through cooperative interactions involving a large set of endocytic proteins [5]. Chief among these are adaptor proteins, which, as the name suggests, link membrane components with the outer layer of the vesicle coat, which is composed of clathrin trimers (Figure 1, inset). While the principal role of clathrin-coated buds is to gather appropriate transmembrane proteins, generically designated “cargo,” for selective delivery to the cell interior, cargo capture is not the driving force for the deposition of coat components at a nascent bud site. AP-2, a major adaptor complex within clathrin-coated structures, has two separate cargo-binding surfaces that are probably both inaccessible when AP-2 first docks onto the plasma membrane [6],[7]. This means that although cargo depends on a sorting signal(s) for its incorporation into clathrin-coated vesicles, recognition of these signals is unlikely to be the event that recruits adaptors and thus allows clathrin coats to form on bare membrane. Instead, the rare and spatially restricted phospholipid phosphatidylinositol 4,5-bisphosphate (PtdIns(4,5)P2) seems to play a major role in placing coat protomers on the plasma membrane to begin clathrin assembly [8]–[11]; AP-2 and several other important coat and accessory proteins bind physically to PtdIns(4,5)P2\n",
      "[5]. Perturbing PtdIns(4,5)P2 production in cultured cells leads to an almost immediate dissolution of preexisting clathrin-coated structures at the cell surface [8],[10],[11].\n",
      "\n",
      "Because transmission electron microscope (EM) images typically reveal isolated, invaginating coated buds all along the cell surface, and clathrin immunolabeling often shows a profusion of small, separated puncta apparently randomly scattered over the surface membrane (Figure 2), it seems reasonable to suspect that clathrin-coated vesicles might form de novo for each internalization cycle. There is indeed evidence for this from live-cell imaging. In the unicellular yeast Saccharomyces cerevisiae, the predictable kinetic behavior of coat components has led to a thorough cataloging of temporally resolved protein entry and exit at single-turnover endocytic sites [12]. In BS-C-1 cells, an African green monkey–derived cell line, clathrin coats at the surface are similarly uniform. The stereotyped behavior of these structures has allowed the definition of coat lifetimes and revealed different types of failure events [13],[14] for these canonical constructions, which are known as clathrin-coated pits. Most importantly, insufficient (or perhaps inappropriate) cargo packaging appears to presage nonproductive collapse of an incipient bud [13],[14]. So, while cargo clearly does not actively recruit coat machinery to the membrane, it plays an important role in driving the process forward to the next step: the budding of vesicles.\n",
      "\n",
      "Yet, in other cell lines [15]–[19] and isolated primary cells [20], the size distribution of clathrin-coated structures on the cell surface is far less regular than in BS-C-1 cells. For example, in HeLa cells, in addition to transient diffraction-limited objects (<200 nm), large, long-lived and rather sedentary clathrin spots (>500 nm) are observed (Figure 2). Both EM [21],[22] and time-resolved fluorescence imaging techniques, like total internal reflection fluorescence microscopy (TIR-FM) [17],[18],[23],[24], have been used to visualize the bulky clathrin structures on the basal adherent surface, but EM-based visualization of isolated dorsal plasma membrane also shows regions of extensive flat clathrin lattice [25],[26]. Why are there different clathrin assemblies at the plasma membrane and what, if any, is the functional significance of this dichotomy? The variability in position, size, and dynamic behavior of diverse clathrin structures has made global computational analysis of large data sets of time-resolved events very challenging. For one thing, the kinetic inconsistency makes modeling difficult and much depends upon whether, despite morphological and temporal plasticity, the sorting and functional properties of the different patches is basically the same.\n",
      "\n",
      "In this issue of PLoS Biology, the Kirchhausen laboratory delves into this issue by utilizing quantitative live-cell imaging of several distinct cell types [27]. Their overarching conclusion is that two mechanistically distinct modes of clathrin assembly and internalization occur at the ventral plasma membrane of different cells. They deduce that rounded buds correspond to de novo–forming, canonical clathrin-coated pits on naked membrane, while clathrin-coated “plaques” are equivalent to the persistent, flat clathrin sheets, and are found only on the basal adherent surface. A pivotal finding is that plaques apparently remain roughly planar throughout, including when an abrupt inward trajectory signifies entry into the cell interior. In curved coated pits, the distribution of AP-2 and epsin, another adaptor, relative to the clathrin coat appears asymmetric, but not in plaques [27]. This again suggests that the underlying plasma membrane is not deformed into a spherical vesicle, typical of most coat-mediated transport events; plaques seemingly maintain a constant arrangement throughout their functional lifetime.\n",
      "\n",
      "Saffarian et al. provocatively argue that their characterization of general plaque behavior rationalizes a rather discrepant literature, yet the work also raises several fundamental questions. Foremost is whether the plaques they catalog are generally equivalent to the extensive, long-lived, and immobile clathrin patches seen by others. In contrasting ultrastructural studies from other laboratories, the flat patches can be considerably larger [21],[25],[26],[28],[29], and internalization en masse could possibly generate a large puncture in the basal membrane unless much circumferential uncoated membrane is also incorporated into the incoming vesicle, with concomitant reorganization of the underlying surface bilayer (Figure 3). Do plaques invariably enter as intact structures? And, if so, how mechanistically does this occur without compromising the bulk membrane structure? Curiously, despite being plentiful at the adherent surface, thin-section EM images of plaques captured precisely at the instant of internalization are not available. Saffarian et al. assert that the slow relative rate of plaque internalization makes this visualization unlikely. Still, a striking feature of clathrin structures in freeze-etch images of the adherent cell surface is the frequent close proximity of emerging rounded buds to adjacent flat arrays (Figure 2). Corroborating thin-section EM images have been published previously in which buds within, or immediately adjacent to, plaques are plainly seen [21]. One interpretation of this juxtaposed positioning is that flat clathrin arrays could operate as staging scaffolds for spherical bud production. This idea is in accord with observed fluctuations in TIR-FM fluorescence intensity within the persistent lattice population [20], which are compatible with loss of (peripheral) subregions of an extended patch, leaving portions remaining at the plasma membrane [15]. Labeled cargo molecules also have been seen emerging from stationary clathrin patches [20],[26].\n",
      "\n",
      "Next, we do not understand clearly how, when compared with pits, flat arrays are differentially nucleated and apparently restricted to the adherent surface of the cell. The requirement for a very large excess of hexagonal facets to construct a planar lattice differs obviously from de novo–nucleated buds. Yet, flat lattices must require PtdIns(4,5)P2 for assembly, as consumption of this lipid leads to prompt loss of most clathrin structures and adaptors at the ventral surface [10],[11]. Fluorescence recovery after photobleaching (FRAP) experiments indicate that during assembly, clathrin and AP-2 molecules rapidly enter and exit small and large structures alike [16],[30]. That both structures are dynamic at the microscopic level suggests similar overall apparatus and assembly mechanisms. And if cargo is needed to stabilize coats [13],[14], then long-lived plaques must contain and sequester cargo, just as pits do. This is borne out experimentally: fluorescently tagged transferrin (a serum iron transporter that engages the transmembrane transferrin receptor for clathrin-dependent import of iron into the cell interior) labels essentially all surface clathrin structures in HeLa and other cells [17],[19],[20],[30]. The density of transferrin receptor in flat lattice is proportional to receptor concentration [26], and the rate and quantitative nature of transferrin uptake makes it highly unlikely that cargo concentrated within plaques fails to internalize rapidly. Thus, morphologically discernible clathrin structures do appear to cluster the same constitutively internalized cargo.\n",
      "\n",
      "Another (possibly related) issue is, what prevents the flat clathrin arrays from forming invaginated buds? Perhaps information can be gleaned from comparison with another membrane compartment where flat clathrin arrays also form with no evidence of rounded bud production: on early endosomes maturing into multivesicular bodies (Figure 1). Originally discovered in 1964 [31], we now know that these endosomal clathrin assemblies operate by sequestering cargo, just like clathrin-coated structures at the plasma membrane [32]. However, these so-called bilayered clathrin coats do not contain AP-2 and have an unusual EM morphology that is not seen at plasma membrane plaques. The odd appearance of bilayered clathrin coats could indicate inclusion of structural components that preclude lattice curvature. In canonical, de novo–forming rounded buds, it is thought that the force to sculpt the plasma membrane may come from assembling clathrin, which has inherent curvature when pentagonal facets are incorporated into the lattice [22],[27],[33]; or, instead of inducing curvature itself, clathrin may stabilize curvature resulting from thermal fluctuation–driven membrane rearrangements [34]. Do plasma membrane plaques then, like bilayered clathrin coats on early endosomes, incorporate some additional structural component(s) that blocks clathrin-mediated induction or stabilization of membrane curvature?\n",
      "\n",
      "An alternative model for what prevents the basally located, flat clathrin arrays from forming invaginated buds is that it is due to a unique role for the actin cytoskeleton in plaque formation, coupled with the strength of adhesion of the basal cell surface to the underlying substrate on which cells are growing. Saffarian et al. find that actin nucleation is unnecessary for the budding of spherical coats, although it is worth noting that at the apical surface of polarized epithelial cells, where clathrin buds are incontestably spherical, actin does regulate vesicle internalization [35] and also drives entry of rounded clathrin-coated structures housing vesicular stomatitis virus [36]. In contrast to what Saffarian et al. observe for bud formation, nucleation of branched actin microfilaments appears to drive plaque movement into the cell [27] (Figure 3). This conclusion is based on the observations that depolymerization of the actin cytoskeleton with the sponge toxin latrunculin A arrests development and internalization of extant plaques and that the branched actin regulators cortactin and Arp2/3 build up at plaques just prior to movement away from the cell cortex [27]. Because latrunculin A application also prevents the formation of new plaques [27], an additional activity of the actin cytoskeleton may be to maintain the planar topology of plaques, perhaps in concert with resistance to deformation caused by tight cell adhesion to the underlying substrate. These observations of actin contributions to plaque formation in particular are intriguing, as the closest mechanistic parallels to the behavior of plaques seem to come from cortical actin patches in S. cerevisiae, the sites of clathrin-mediated endocytosis [12]. While absolutely actin-dependent, cortical patches remodel the plasma membrane into tubulovesicular profiles upon internalization [37], quite unlike what is suggested for higher eukaryotic plaques.\n",
      "\n",
      "Irrespective of mechanism, the current schematic depiction suggests that uptake of a flat clathrin sheet leads to extraneous (noncoated) membrane around the perimeter of the plaque also being internalized (Figure 3). Superficially, this seemingly defies the whole elegant selectivity of coat-mediated sorting. Two important questions arise from this model: how can this membrane excess prevent endocytosis of inappropriate plasma membrane segments, and how is scission regulated at the molecular level?\n",
      "\n",
      "But perhaps the most important lingering question is what the functional significance of the flat clathrin arrays is, if they have no operative relationship to buds. Two different types of clathrin assemblies could be a physical manifestation of compositionally discrete sorting stations operating in parallel to presort cargo at the cell surface. Data to support the idea of cargo-selective clathrin coats are accumulating [38]–[41], but do not seem to strictly reflect selective partitioning of different membrane-embedded proteins into either pits or plaques. There are, in fact, suggestions that even in BS-C-1 cells, which lack plaques, different types of clathrin sorting structures occur [40]. Doubtless, more work is needed to establish the precise functional interrelationships between different types of clathrin-coated structures, but, unarguably, the new results from Saffarian et al. have given cell biologists much to ponder.\n",
      "\n",
      "Schematic illustration of a cultured cell showing surface-positioned clathrin-coated buds, ventrally located large, flat clathrin “plaques,” and the major internal endosomal sorting stations. After clathrin coat uncoating, transport vesicles quickly fuse with the peripheral early endosome compartment, mingling incoming cargo molecules in this initial sorting endosome. Transmembrane cargo can return either directly to the plasma membrane from the early endosome, or be sorted into tubules that are delivered to the juxtanuclear recycling endosome compartment, from which cargo can also be directed back to the cell surface. The bulbous vacuolar portion of the early endosome, containing a flat, bilayered clathrin coat, matures into a multivesicular body for delivery of selected components to lysosomes for degradation. The inset shows the basic composition and organization of a clathrin-coated vesicle, with the three major layers: the inner membrane vesicle with various embedded transmembrane cargo (blue and green), an intermediate layer of adaptors including AP-2 (gray), and the outer clathrin polyhedral lattice (red).\n",
      "\n",
      "(A) Confocal optical section of a HeLa cell immunolabeled with antibodies to AP-2 to reveal clathrin-coated structures on the adherent plasma membrane. Selected examples of diffraction-limited spots (arrowheads) and large clathrin assemblies (arrows) are shown. (B) Freeze-etch EM image of the adherent surface of a cultured cell, showing both flat and rounded, budding polygonal clathrin structures (pseudocolored in red) on the plasma membrane and the proximity of budding vesicles to the planar sheets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chapter in r['content']['chapters']:\n",
    "    for paragraph in chapter[0]['paragraphs']:\n",
    "        print(paragraph)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No chapters in PMC_3472976\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-ddacd84d4e65>\", line 34, in return_paragraphs\n",
      "    for paragraph in chapter['paragraphs']:\n",
      "TypeError: string indices must be integers\n",
      "ERROR:root:No chapters in PMC_521730\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-ddacd84d4e65>\", line 34, in return_paragraphs\n",
      "    for paragraph in chapter['paragraphs']:\n",
      "TypeError: string indices must be integers\n",
      "ERROR:root:No chapters in PMC_1084337\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-ddacd84d4e65>\", line 34, in return_paragraphs\n",
      "    for paragraph in chapter['paragraphs']:\n",
      "TypeError: string indices must be integers\n",
      "ERROR:root:No chapters in PMC_4917243\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-ddacd84d4e65>\", line 34, in return_paragraphs\n",
      "    for paragraph in chapter['paragraphs']:\n",
      "TypeError: string indices must be integers\n",
      "ERROR:root:No chapters in PMC_3075230\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-ddacd84d4e65>\", line 34, in return_paragraphs\n",
      "    for paragraph in chapter['paragraphs']:\n",
      "TypeError: string indices must be integers\n",
      "ERROR:root:No chapters in PMC_2930862\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-ddacd84d4e65>\", line 34, in return_paragraphs\n",
      "    for paragraph in chapter['paragraphs']:\n",
      "TypeError: string indices must be integers\n",
      "ERROR:root:No chapters in PMC_2730035\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-11-ddacd84d4e65>\", line 34, in return_paragraphs\n",
      "    for paragraph in chapter['paragraphs']:\n",
      "TypeError: string indices must be integers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total journals: 1\n"
     ]
    }
   ],
   "source": [
    "# filter_publications = [\"WWW\", \"ICSE\", \"VLDB\", \"JCDL\", \"TREC\",  \"SIGIR\", \"ICWSM\", \"ECDL\", \"ESWC\", \"TPDL\", \n",
    "filter_publications = [ \"PLoS Biology\"]#, \"Breast Cancer Research\", \"BMC Evolutionary Biology\", \"BMC Genomics\", \"BMC Biotechnology\",\n",
    "#                         \"BMC Neuroscience\", \"Genome Biology\", \"PLoS Genetics\", \"Breast Cancer Research : BCR\", \n",
    "#                        \"Genome Biology and Evolution\", \"Breast Cancer Research and Treatment\"]\n",
    "\n",
    "list_of_pubs = []\n",
    "\n",
    "for publication in filter_publications:\n",
    "    mongo_string_search = {'$or': [{'$and': [{'booktitle': publication}, {'content.fulltext': {'$exists': True}}]} ,\n",
    "                                   {'$and': [{'journal': publication},   {'content.fulltext': {'$exists': True}}]} ]}\n",
    "    list_of_pubs.append(return_paragraphs(mongo_string_search, db))\n",
    "\n",
    "print(\"Total journals:\", len(list_of_pubs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for pubs in list_of_pubs:\n",
    "    for paper in pubs:\n",
    "        actions = []\n",
    "        cleaned = []\n",
    "        datasetsent = []\n",
    "        othersent = []\n",
    "        \n",
    "        for paragraph in paper['paragraphs']:\n",
    "            if paragraph == {}:\n",
    "                continue\n",
    "            lines = (sent_detector.tokenize(paragraph.strip()))\n",
    "            \n",
    "            if len(lines) < 3:\n",
    "                continue\n",
    "\n",
    "            for i in range(len(lines)):\n",
    "                words = nltk.word_tokenize(lines[i])\n",
    "                lengths = [len(x) for x in words]\n",
    "                average = sum(lengths) / len(lengths)\n",
    "                if average < 4:\n",
    "                    continue\n",
    "                    \n",
    "                twosentences = ''\n",
    "                try:\n",
    "                    twosentences = lines[i] + ' ' + lines[i-1]\n",
    "\n",
    "                except:\n",
    "                    twosentences = lines[i] + ' ' + lines[i+1]\n",
    "                    \n",
    "                datasetsent.append(twosentences)\n",
    "\n",
    "            #cleaned.append(paragraph)\n",
    "\n",
    "        for num, parag in enumerate(datasetsent):\n",
    "            actions.append({\n",
    "                \"_index\": \"twosent\",\n",
    "                \"_type\": \"twosentnorules\",\n",
    "                \"_id\": paper['_id'] + str(num),\n",
    "\n",
    "                \"_source\" : {\n",
    "                    \"title\" : paper['title'],\n",
    "                    \"content.chapter.sentpositive\" : parag,\n",
    "                    \"paper_id\":paper['_id']\n",
    "                }})\n",
    "            \n",
    "        if len(actions) == 0:\n",
    "            continue\n",
    "\n",
    "#         res = helpers.bulk(es, actions)\n",
    "#         print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Using ES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 19637 Hits:\n",
      "Selection and ranking of text from highly imperfect transcripts for retrieval of video content.\n",
      "INTRODUCTION\n",
      "Search and retrieval of video content rely heavily on cues drawn from text in the form of speech from automatic speech recognition (ASR) and writing from optical character recognition (OCR). Existing multimedia content browsers for news \n",
      "TEXT SELECTION AND RANKING\n",
      "We apply relevant external indices to filter raw transcripts. We have shown that course textbook indices are effective filters for lecture videos \n",
      "SIGIR 2007 Proceedings Poster \n",
      "We assign to each identified phrase a numerical rank, which is used to emphasize text differently in the browser interface (\n",
      "INTERFACE AND EVALUATION\n",
      "We have compared two user interfaces (\n",
      "REFERENCES\n",
      "SIGIR 2007 Proceedings Poster \n",
      "\n",
      "__________\n",
      "Simplified similarity scoring using term ranks.\n",
      "INTRODUCTION\n",
      " Two of the most important features of a document ranking mechanism are its retrieval effectiveness and querying efficiency. The former reflects the ability of the mechanism to retrieve relevant documents at the top of the ranking, while the latter represents the desire to control per-query processing time. Other features such as index size, index building speed, or memory usage during indexing and querying are also important, but, to some extent, less crucial. A large body of research work has been devoted to improving retrieval effectiveness, and has led to the development of a range of innovative retrieval models and weighting schemes. The effectiveness of ranking mechanisms is demonstrated through empirical Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. \n",
      "S d,q as 1 W d · X t∈d∩q (1 + log e f d,t ) · (1 + log e fq,t) · log e (1 + f a t ft ) (1) \n",
      "where f a t is the average value of ft over D, \n",
      "and W d = (1 − s) + s · W d /W a d \n",
      "is the normalized weight of d and can be pre-calculated at indexing time with the slope s = 0.7 \n",
      "X t∈d∩q ln N − ft + 0.5 ft + 0.5 · f d,t 0.5 + 1.5 · W d /W a d + f d,t . (2) \n",
      "This computation can be implemented using the same information as is used in the vector space approach, but in an operational sense is potentially less efficient than the vector space computation, because of the use of the normalized document weight each time a pointer in an inverted list is examined. In language models, the similarity score S d,q is replaced by the conditional probability P (q | M d ) of generating the query q given a model M d of d. Ponte and Croft \n",
      "P (q | M d ) = Y t∈q P (t | M d ) · Y t / ∈q (1 − P (t | M d )) \n",
      "where the probability of producing and not producing the terms in the query are taken into account. However, the computation of P (q | M d ) is less efficient than that of S d,q in the BM25 scheme described above. Experiments with language model approaches show that it gives good retrieval effectiveness, and the joint statement by Allan et al. \n",
      "Ω d = (ω d,t 1 , ω d,t 2 \n",
      " , . . . , ω d,tn d ) as the impact vector for d. Abusing mathematical definitions, we say that, in the case of the vector space model and BM25, the similarity score S d,q is the scalar vector product of the document impact vector Ω d and the query impact vector Ωq. The abuse lies on the projection of both the document term list T d and the query term list Tq to T d ∩ Tq to allow the mathematical scalar vector product. That is, we write \n",
      "S d,q = Ω d · Ωq = X t∈d∩q ω d,t · ωq,t . \n",
      "One classical interpretation of these formulations, for document impacts in particular, is that they are the product of a term frequency TF component and an inverse document frequency component IDF, representing respectively the importance of the term in the document, and the importance of the term in the collection. We will return to the TF-IDF notion below. \n",
      "APPROACH\n",
      "Anh and Moffat \n",
      "L = min d∈D,t∈T d ω c d,t , and U = max d∈D,t∈T d ω c d,t . \n",
      "In this work the transformed integer values suggested by Anh and Moffat are denoted by ω g d,t , and their scoring method as Global-By- Value, summarizing its key attributes – the evaluation is global, and the assignment of impacts is accomplished using a transformation based on numeric values. Impact transformation improves on the standard cosine mechanisms in two key areas. First, since the impacts ω g d,t are small integers , they can be stored directly, rather than f d,t values, thereby reducing the amount of computation required as queries are being processed. Second, there is no need to exhaustively evaluate the standard vector space similarity score. The inverted lists can be impact-sorted, with each inverted list structured as a sequence of equal-impact blocks, with the blocks stored in decreasing impact order. The blocks of the relevant inverted lists can then be processed in an interleaved manner in decreasing order of the product between query impact and block impact. Not all the blocks need to be processed, and effective pruning can be achieved. Moreover, since all of the impacts are small integers, the accumulation process can be combined in parallel with the selection and sort process by using a score-indexed priority queue data structure. Anh and Moffat \n",
      " @BULLET provides fast ranking, by virtue of its use of integer compu- tations; @BULLET is amenable to dynamic pruning; and @BULLET provides a high level of retrieval effectiveness. \n",
      "The next few sections address these desiderata. \n",
      "QUANTITATIVE IMPACTS\n",
      " The most direct way of incorporating a document-centric viewpoint into the impact definition is to employ the same process of impact transformation described by Anh and Moffat \n",
      "ω c d,t = (1 + log e f d,t ) · log e (1 + f m ft ) . \n",
      "The population of ω c d,t for each d ∈ D is then used to compute \n",
      "L d = min t∈T d ω c d,t and U d = max t∈T d ω c d,t . \n",
      "Next, each value ω c d,t of that population is transformed to \n",
      "ω d d,t = — k · log ω c d,t − log L d log U d − log L d + + 1, \n",
      "where is an arbitrarily small positive number which ensures that the impacts ω d d,t do not exceed k, and k is the number of distinct impact scores, and controls the fidelity of the approximation. Within each document d, the transformation reduces the gaps between the low and high original impacts in a logarithmic way, and allows the collective effort of a number of low impacts to have an increased chance of overcoming a single high impact value. In other words, a document that shares a larger number of common terms with the query now has a higher similarity score than previously . This transformation scheme is referred to as Local-By-Value – compared to Global-By-Value, the difference is that the initial scoring (prior to the conversion to integer impacts) is based on attributes local to each document. It is interesting to compare the two approaches. With the Global- By-Value method, the largest impact value in a document d1 might still be small compared to the largest impact in document d2. By way of contrast, the Local-By-Value method forces a re-evaluation process that adjusts the impact values so that, over the set of documents D, the largest and smallest impact values of each document are roughly the same. As an intuitive justification, consider two documents which have about the same term appearance statistics, but one of which uses many rare words while the other tends to use more \" conventional \" words. In this case the Global-By-Value method assigns a greater number of high impacts to the first document than it does to the second one. On the other hand, the Local- By-Value method can assign high impact values to the \" conventional \" words in the second document. Consequently, when a query with \" conventional \" words is issued, the second document is more likely to be retrieved by Local-By-Value than by Global-By-Value. \n",
      "QUALITATIVE IMPACTS\n",
      "Now suppose that we are required to manually assign an integral impact between 1 and k to each distinct term of some document. We would instinctively expect to assign a relatively small number of high values, and a relatively large number of low values – in human terms, a reflection of the observation that \" ordinary \" is shared among many, while \" outstanding \" is less frequent. The Local-By-Value method, unfortunately, does not guarantee a distribution in which only a few things are deemed to be \" outstanding \" , and provides little control over the distribution of the assigned impact values in any given document. That is, the precise value of cosine impacts is perhaps not a good basis for retrieval, and the set of impact ranks (ordered positions when sorted into order) might be a better choice, thereby ensuring that the complete range of impact scores is used in every document. In this alternative regime, the term in a document with the highest score is given an impact of k, and a group of terms with low scores is given an impact of 1, with the assignment in between based on the relative position of each term in the sorted list of scores for that document. One problem with using ranks rather than scores is the need to choose a partitioning of the n d impacts into k groups so that the number of elements in the groups grows in the desired way. We minimize this problem by choosing a mechanism that does not employ any further tuning parameters, but does embody the \" many ordinary \" principle. Taking xi to be the number of impacts of value i (where i is between 1 and k inclusive), we build a geometric sequence with xi ≈ B · xi+1. To anchor the values, we then further set x k = B − 1. The solution to these two constraints is B = (n d + 1) 1/k . All of the xi values are then appropriately rounded to integers, with carry-forward of residual discrepancies. In practice, for typical values of k and n d , B is between 1 and 3, meaning that zero, one, or two terms in each document are identified as being the \" most important \" ones, and assigned an impact of k. \n",
      "@BULLET Local-By-Rank-(TF × IDF): \n",
      " The term list is sorted in increasing order of the localized impact used in the Local- By-Value method, and then converted to rank-based impact scores. \n",
      "@BULLET Local-By-Rank-(IDF, TF): \n",
      " The term list is sorted in increasing order of ft, with ties on ft broken using decreasing order on f d,t as a secondary key. In this arrangement, the IDF component is presumed to dominate the TF component; the nomenclature reflects the lexicographic sort ordering. \n",
      "@BULLET Local-By-Rank-(TF, IDF): \n",
      "The IDF component is a statistic of the collection, rather than of a particular document. The Local-By-Rank-(IDF, TF) method, in that sense, does not reflect our \" one document at a time \" theme. From the point of view of a single document, the TF component should dominate . In this third arrangement, the term list is sorted in decreasing order of f d,t , with ties broken by using increasing order on ft as a secondary key. \n",
      "@BULLET Local-By-Rank-(TF): \n",
      " This variant eliminates collection dependent values completely, and orders the term list solely based on f d,t . Terms with the same f d,t value are all allocated the same impact value, namely the impact of the median term with this f d,t . Of the four Local-By-Rank alternatives , this one might result in the final distribution of impact values within the document varying from the geometric target distribution. \n",
      "One slightly complication with our schemes is that of common words. In most English prose the word \" the \" is the most frequent, but it probably should not be assigned an impact of k in every document , since the appearance of just two or three common words in the term list for each document then means that only k < k different impact values are available to express the importance of the more meaningful terms. To bypass this dilemma, and ensure that the high impacts are not subverted by common words, all stop words are given an artificial f d,t score of one during the sorting phase of the impact assignment process. The file stoplist.orig at the site http://goanna.cs.rmit.edu.au/~jz/resources/ stopping.zip provides a suitable list of 600 common words, and we used that list as the basis for this adjustment to the f d,t values. Finally in this section, note that the number of different ft values is high in any non-trivial document collection. In all but the last of these four sorting rules there is only a small chance that two different terms in the same document have the same sort key value, and further tie-breaking is not critical. In the Local-By-Rank-(TF) method, ties are handled explicitly. \n",
      "TRAINING\n",
      "The discussion and various conjectures of the previous section can be summarized as a multi-part hypothesis: @BULLET localized statistics provide similarity estimates that are not inferior to those derived from global statistics; @BULLET using relative term orderings (Local-By-Rank methods) to determine the impacts is as good as using calculated scores (Local-By-Value methods); @BULLET TF is more important than IDF in the Local-By-Rank meth- ods; @BULLET improving the impact ordering by putting stop words at the end is plausible; and @BULLET retrieval effectiveness is consistent except when k is very small. \n",
      "In this section we examine these claims, and explore the behavior of the ranking mechanism in a training environment. In particular, an appropriate value for k needs to be set. Taking k too small allows compact indexes and fast evaluation, but may harm retrieval effectiveness . Conversely, taking k too large provides more fidelity in the scoring process, but increases the size of the compressed index. The bigger hypothesis – that the new approach provides excellent retrieval effectiveness compared to the vector space model, BM25, and language model alternatives – is considered in the next section, using different collections, and once the details of our documentcentric qualitative-impact system are finalized. The dataset used in this section is WSJ2 – a subset of Disk2 of the TREC corpus, see trec.nist.gov. Collection WSJ2 is a homogeneous set of documents, and contains the text of the \n",
      "(1 + log e fq,t) × (log e (1 + f m /ft)) , \n",
      "where f m is the maximum value of ft over the collection, and fq,t is the number of times term t appears in the query. 2. The set of weights is transformed to a set of integer query impacts by linear scaling so that the maximum query term impact is exactly k. \n",
      " The different procedure (to document impact computation) is required because, in general, queries cannot be expected to contain sufficiently many terms for ranks to be sensibly employed. Also worth noting is that this calculation still includes ft in an IDF factor , but that it is not required until the index has been completed and queries are being processed. The first set of experiment in this series, shown in \n",
      "Collection \n",
      "EFFICIENCY\n",
      "There are two primary aspects to retrieval efficiency: the speed at which queries can be resolved; and the volume of index space occupied by the compressed inverted file. In order to provide a baseline for measurements of these attributes, we make use of the mg system, available from www.cs.mu.oz.au/mg/. It employs a document-sorted inverted index storing d-gaps alternating with f d,t values, and processes queries using floating-point computations based around equation 1. In particular, mg provided the basis for the Pivoted and BM25 results shown in \n",
      "\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index=\"ir\", body={\"query\": {\"match_all\": {}}}, size = 2)\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_source']['title'])\n",
    "    print(hit['_source']['text'])\n",
    "    file = hit['_source']['text']\n",
    "    print('_'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'conf_sigir_AnhM05',\n",
       " '_index': 'ir',\n",
       " '_score': 1.0,\n",
       " '_source': {'publication': 'SIGIR',\n",
       "  'text': 'INTRODUCTION\\n Two of the most important features of a document ranking mechanism are its retrieval effectiveness and querying efficiency. The former reflects the ability of the mechanism to retrieve relevant documents at the top of the ranking, while the latter represents the desire to control per-query processing time. Other features such as index size, index building speed, or memory usage during indexing and querying are also important, but, to some extent, less crucial. A large body of research work has been devoted to improving retrieval effectiveness, and has led to the development of a range of innovative retrieval models and weighting schemes. The effectiveness of ranking mechanisms is demonstrated through empirical Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. \\nS d,q as 1 W d · X t∈d∩q (1 + log e f d,t ) · (1 + log e fq,t) · log e (1 + f a t ft ) (1) \\nwhere f a t is the average value of ft over D, \\nand W d = (1 − s) + s · W d /W a d \\nis the normalized weight of d and can be pre-calculated at indexing time with the slope s = 0.7 \\nX t∈d∩q ln N − ft + 0.5 ft + 0.5 · f d,t 0.5 + 1.5 · W d /W a d + f d,t . (2) \\nThis computation can be implemented using the same information as is used in the vector space approach, but in an operational sense is potentially less efficient than the vector space computation, because of the use of the normalized document weight each time a pointer in an inverted list is examined. In language models, the similarity score S d,q is replaced by the conditional probability P (q | M d ) of generating the query q given a model M d of d. Ponte and Croft \\nP (q | M d ) = Y t∈q P (t | M d ) · Y t / ∈q (1 − P (t | M d )) \\nwhere the probability of producing and not producing the terms in the query are taken into account. However, the computation of P (q | M d ) is less efficient than that of S d,q in the BM25 scheme described above. Experiments with language model approaches show that it gives good retrieval effectiveness, and the joint statement by Allan et al. \\nΩ d = (ω d,t 1 , ω d,t 2 \\n , . . . , ω d,tn d ) as the impact vector for d. Abusing mathematical definitions, we say that, in the case of the vector space model and BM25, the similarity score S d,q is the scalar vector product of the document impact vector Ω d and the query impact vector Ωq. The abuse lies on the projection of both the document term list T d and the query term list Tq to T d ∩ Tq to allow the mathematical scalar vector product. That is, we write \\nS d,q = Ω d · Ωq = X t∈d∩q ω d,t · ωq,t . \\nOne classical interpretation of these formulations, for document impacts in particular, is that they are the product of a term frequency TF component and an inverse document frequency component IDF, representing respectively the importance of the term in the document, and the importance of the term in the collection. We will return to the TF-IDF notion below. \\nAPPROACH\\nAnh and Moffat \\nL = min d∈D,t∈T d ω c d,t , and U = max d∈D,t∈T d ω c d,t . \\nIn this work the transformed integer values suggested by Anh and Moffat are denoted by ω g d,t , and their scoring method as Global-By- Value, summarizing its key attributes – the evaluation is global, and the assignment of impacts is accomplished using a transformation based on numeric values. Impact transformation improves on the standard cosine mechanisms in two key areas. First, since the impacts ω g d,t are small integers , they can be stored directly, rather than f d,t values, thereby reducing the amount of computation required as queries are being processed. Second, there is no need to exhaustively evaluate the standard vector space similarity score. The inverted lists can be impact-sorted, with each inverted list structured as a sequence of equal-impact blocks, with the blocks stored in decreasing impact order. The blocks of the relevant inverted lists can then be processed in an interleaved manner in decreasing order of the product between query impact and block impact. Not all the blocks need to be processed, and effective pruning can be achieved. Moreover, since all of the impacts are small integers, the accumulation process can be combined in parallel with the selection and sort process by using a score-indexed priority queue data structure. Anh and Moffat \\n @BULLET provides fast ranking, by virtue of its use of integer compu- tations; @BULLET is amenable to dynamic pruning; and @BULLET provides a high level of retrieval effectiveness. \\nThe next few sections address these desiderata. \\nQUANTITATIVE IMPACTS\\n The most direct way of incorporating a document-centric viewpoint into the impact definition is to employ the same process of impact transformation described by Anh and Moffat \\nω c d,t = (1 + log e f d,t ) · log e (1 + f m ft ) . \\nThe population of ω c d,t for each d ∈ D is then used to compute \\nL d = min t∈T d ω c d,t and U d = max t∈T d ω c d,t . \\nNext, each value ω c d,t of that population is transformed to \\nω d d,t = — k · log ω c d,t − log L d log U d − log L d + + 1, \\nwhere is an arbitrarily small positive number which ensures that the impacts ω d d,t do not exceed k, and k is the number of distinct impact scores, and controls the fidelity of the approximation. Within each document d, the transformation reduces the gaps between the low and high original impacts in a logarithmic way, and allows the collective effort of a number of low impacts to have an increased chance of overcoming a single high impact value. In other words, a document that shares a larger number of common terms with the query now has a higher similarity score than previously . This transformation scheme is referred to as Local-By-Value – compared to Global-By-Value, the difference is that the initial scoring (prior to the conversion to integer impacts) is based on attributes local to each document. It is interesting to compare the two approaches. With the Global- By-Value method, the largest impact value in a document d1 might still be small compared to the largest impact in document d2. By way of contrast, the Local-By-Value method forces a re-evaluation process that adjusts the impact values so that, over the set of documents D, the largest and smallest impact values of each document are roughly the same. As an intuitive justification, consider two documents which have about the same term appearance statistics, but one of which uses many rare words while the other tends to use more \" conventional \" words. In this case the Global-By-Value method assigns a greater number of high impacts to the first document than it does to the second one. On the other hand, the Local- By-Value method can assign high impact values to the \" conventional \" words in the second document. Consequently, when a query with \" conventional \" words is issued, the second document is more likely to be retrieved by Local-By-Value than by Global-By-Value. \\nQUALITATIVE IMPACTS\\nNow suppose that we are required to manually assign an integral impact between 1 and k to each distinct term of some document. We would instinctively expect to assign a relatively small number of high values, and a relatively large number of low values – in human terms, a reflection of the observation that \" ordinary \" is shared among many, while \" outstanding \" is less frequent. The Local-By-Value method, unfortunately, does not guarantee a distribution in which only a few things are deemed to be \" outstanding \" , and provides little control over the distribution of the assigned impact values in any given document. That is, the precise value of cosine impacts is perhaps not a good basis for retrieval, and the set of impact ranks (ordered positions when sorted into order) might be a better choice, thereby ensuring that the complete range of impact scores is used in every document. In this alternative regime, the term in a document with the highest score is given an impact of k, and a group of terms with low scores is given an impact of 1, with the assignment in between based on the relative position of each term in the sorted list of scores for that document. One problem with using ranks rather than scores is the need to choose a partitioning of the n d impacts into k groups so that the number of elements in the groups grows in the desired way. We minimize this problem by choosing a mechanism that does not employ any further tuning parameters, but does embody the \" many ordinary \" principle. Taking xi to be the number of impacts of value i (where i is between 1 and k inclusive), we build a geometric sequence with xi ≈ B · xi+1. To anchor the values, we then further set x k = B − 1. The solution to these two constraints is B = (n d + 1) 1/k . All of the xi values are then appropriately rounded to integers, with carry-forward of residual discrepancies. In practice, for typical values of k and n d , B is between 1 and 3, meaning that zero, one, or two terms in each document are identified as being the \" most important \" ones, and assigned an impact of k. \\n@BULLET Local-By-Rank-(TF × IDF): \\n The term list is sorted in increasing order of the localized impact used in the Local- By-Value method, and then converted to rank-based impact scores. \\n@BULLET Local-By-Rank-(IDF, TF): \\n The term list is sorted in increasing order of ft, with ties on ft broken using decreasing order on f d,t as a secondary key. In this arrangement, the IDF component is presumed to dominate the TF component; the nomenclature reflects the lexicographic sort ordering. \\n@BULLET Local-By-Rank-(TF, IDF): \\nThe IDF component is a statistic of the collection, rather than of a particular document. The Local-By-Rank-(IDF, TF) method, in that sense, does not reflect our \" one document at a time \" theme. From the point of view of a single document, the TF component should dominate . In this third arrangement, the term list is sorted in decreasing order of f d,t , with ties broken by using increasing order on ft as a secondary key. \\n@BULLET Local-By-Rank-(TF): \\n This variant eliminates collection dependent values completely, and orders the term list solely based on f d,t . Terms with the same f d,t value are all allocated the same impact value, namely the impact of the median term with this f d,t . Of the four Local-By-Rank alternatives , this one might result in the final distribution of impact values within the document varying from the geometric target distribution. \\nOne slightly complication with our schemes is that of common words. In most English prose the word \" the \" is the most frequent, but it probably should not be assigned an impact of k in every document , since the appearance of just two or three common words in the term list for each document then means that only k < k different impact values are available to express the importance of the more meaningful terms. To bypass this dilemma, and ensure that the high impacts are not subverted by common words, all stop words are given an artificial f d,t score of one during the sorting phase of the impact assignment process. The file stoplist.orig at the site http://goanna.cs.rmit.edu.au/~jz/resources/ stopping.zip provides a suitable list of 600 common words, and we used that list as the basis for this adjustment to the f d,t values. Finally in this section, note that the number of different ft values is high in any non-trivial document collection. In all but the last of these four sorting rules there is only a small chance that two different terms in the same document have the same sort key value, and further tie-breaking is not critical. In the Local-By-Rank-(TF) method, ties are handled explicitly. \\nTRAINING\\nThe discussion and various conjectures of the previous section can be summarized as a multi-part hypothesis: @BULLET localized statistics provide similarity estimates that are not inferior to those derived from global statistics; @BULLET using relative term orderings (Local-By-Rank methods) to determine the impacts is as good as using calculated scores (Local-By-Value methods); @BULLET TF is more important than IDF in the Local-By-Rank meth- ods; @BULLET improving the impact ordering by putting stop words at the end is plausible; and @BULLET retrieval effectiveness is consistent except when k is very small. \\nIn this section we examine these claims, and explore the behavior of the ranking mechanism in a training environment. In particular, an appropriate value for k needs to be set. Taking k too small allows compact indexes and fast evaluation, but may harm retrieval effectiveness . Conversely, taking k too large provides more fidelity in the scoring process, but increases the size of the compressed index. The bigger hypothesis – that the new approach provides excellent retrieval effectiveness compared to the vector space model, BM25, and language model alternatives – is considered in the next section, using different collections, and once the details of our documentcentric qualitative-impact system are finalized. The dataset used in this section is WSJ2 – a subset of Disk2 of the TREC corpus, see trec.nist.gov. Collection WSJ2 is a homogeneous set of documents, and contains the text of the \\n(1 + log e fq,t) × (log e (1 + f m /ft)) , \\nwhere f m is the maximum value of ft over the collection, and fq,t is the number of times term t appears in the query. 2. The set of weights is transformed to a set of integer query impacts by linear scaling so that the maximum query term impact is exactly k. \\n The different procedure (to document impact computation) is required because, in general, queries cannot be expected to contain sufficiently many terms for ranks to be sensibly employed. Also worth noting is that this calculation still includes ft in an IDF factor , but that it is not required until the index has been completed and queries are being processed. The first set of experiment in this series, shown in \\nCollection \\nEFFICIENCY\\nThere are two primary aspects to retrieval efficiency: the speed at which queries can be resolved; and the volume of index space occupied by the compressed inverted file. In order to provide a baseline for measurements of these attributes, we make use of the mg system, available from www.cs.mu.oz.au/mg/. It employs a document-sorted inverted index storing d-gaps alternating with f d,t values, and processes queries using floating-point computations based around equation 1. In particular, mg provided the basis for the Pivoted and BM25 results shown in \\n',\n",
       "  'title': 'Simplified similarity scoring using term ranks.',\n",
       "  'year': '2005'},\n",
       " '_type': 'publications'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2683879 Hits:\n",
      "In Section 3, we describe the experimental procedure that we followed to collect the raw data on which the analyses are based. In Section 2, we review related work.\n",
      "__________________________________________________ 0\n",
      "In Section 4, we describe the statistical analysis of the data, the results of the analysis, and the cross-validation procedures and their outcomes. In Section 3, we describe the experimental procedure that we followed to collect the raw data on which the analyses are based.\n",
      "__________________________________________________ 1\n",
      "In Section 5, we offer discussion of the experiment and its results. In Section 4, we describe the statistical analysis of the data, the results of the analysis, and the cross-validation procedures and their outcomes.\n",
      "__________________________________________________ 2\n",
      "There are three main differences between this previous work and our work. They showed that on their subject programs, the final sufficient set determined a higher AM than the Offutt that they also have few complex data structures, making it unclear whether the results of their experiments would carry over to complex C programs and object-oriented programs.\n",
      "__________________________________________________ 3\n",
      "These are the values that we used in the subsequent analysis. The data collection therefore yielded, for each of the seven programs , and for each of the 100 subject test suites, values for AM and for Ami for each i, 1 ≤ i ≤ 108.\n",
      "__________________________________________________ 4\n",
      "In Section 4.2, we describe the results of the model selection procedure on the data from all seven subject programs. In this section, the main section of the paper, we first (Section 4.1) describe alternative approaches to the model selection problem , including the method (cost-based LARS) that we adopted.\n",
      "__________________________________________________ 5\n",
      "This in turn implies that our procedure for applying CBLARS, when applied to the data from all seven subject programs, would yield an accurate prediction of AM scores for test suites of some other, arbitrary eighth program. Our cross-validation indicates that the procedure for applying CBLARS described in Section 4.2, when applied to a set of data from six of our subject programs, yields an accurate prediction of AM scores for test suites of the seventh subject program.\n",
      "__________________________________________________ 6\n",
      "However, larger programs may have more complex control and data flow patterns, which may lead to different results. This threat is mitigated by the facts that the C programs are large and complex enough to include a broad range of control and data structures, and that the three dominant languages in programming today (C, C++ and Java) all use very similar syntax in their non-OO constructs.\n",
      "__________________________________________________ 7\n",
      "We also note that we have not attempted to handle object-oriented constructs. However, larger programs may have more complex control and data flow patterns, which may lead to different results.\n",
      "__________________________________________________ 8\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "res = es.search(index=\"twosent\", body={\"query\": {\"match_all\": {}}}, size = 100)\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    if 'data' in hit['_source']['content.chapter.sentpositive']:\n",
    "        print(hit['_source']['content.chapter.sentpositive'])\n",
    "        print('_'*50,x)\n",
    "        x = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2261716 Hits:\n",
      "Remember that this Is only one use of the data structurel it is accessed in at least four other places in the program.\n",
      "__________________________________________________ 0\n",
      "Also, the cost includes the space as well as time costs, so the calculation must take into account the (sometimes changing) sizes of the data structures extant during the algorithm.\n",
      "__________________________________________________ 1\n",
      "Thus, if we knew the properties of the program totally, it might be reasonable to assl~ne that the failure process would be purely random, reflecting the fluctuations of the input data stream.\n",
      "__________________________________________________ 2\n",
      "We attempted to mitigate this threat by sharing both the \" raw \" data collected during the interviews and the resulting report (this paper) with the participants of the study for their validation.\n",
      "__________________________________________________ 3\n",
      "Amazon would tell you that 'yes, you can use the Elastic MapReduce on healthcare data'.\n",
      "__________________________________________________ 4\n",
      "The information is unstructured and difficult to navigate: \" If you want to know 'I have data with these characteristics, or a system that has these needs, what third party tool should I use?\n",
      "__________________________________________________ 5\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "res = es.search(index=\"devtwosentnew\", body={\"query\": {\"match_all\": {}}}, size = 100)\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    if 'data' in hit['_source']['content.chapter.sentpositive']:\n",
    "        print(hit['_source']['content.chapter.sentpositive'])\n",
    "        print('_'*50,x)\n",
    "        x = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 Hits:\n",
      "PMC_4075597 Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index = \"ir\", body = {\"query\": {\"match\": {\"_id\" : \"PMC_4075597\"}}}, size = 200)\n",
    "\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_id'], hit['_source']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9 Hits:\n",
      "PMC_40755975 {'content.chapter.sentpositive': 'Limonene treated mice showed a significant decrease in wound size, the levels of GITR-expressing cells, and Th1 cytokines as well as substantial down regulation of mRNA expression of the inflammatory mediators compared with the vehicle-treated and diabetic mice. Furthermore, histopathological examination showed complete re-epithelisation, decreased inflammatory cells and presence of granulation tissue in the limonene treated mice.', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755974 {'content.chapter.sentpositive': 'D-limonene, one of the major constituent in citrus essential oils is considered to have antioxidant, hypoglycemic and anti-inflammatory activities [2]. Diabetes can hinder the normal wound healing process by inducing long-term inflammation which can lead to delayed maturation of granulation tissues, reduced wound parallel tension and inhibition of angiogenesis [1].', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755976 {'content.chapter.sentpositive': 'Limonene also significantly up regulated the number of Tregs or it also induced Th17/Treg balance and modulated various pro-inflammatory and anti-inflammatory cytokines and the gene expression of their mediators that mediate inflammation. Limonene treated mice showed a significant decrease in wound size, the levels of GITR-expressing cells, and Th1 cytokines as well as substantial down regulation of mRNA expression of the inflammatory mediators compared with the vehicle-treated and diabetic mice.', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755970 {'content.chapter.sentpositive': 'In the present study, we investigated the effects of topical administration of d-limonene (50mg/kg and 100mg/kg; daily in acetone) on the key mediators of wound healing, namely T cell subsets, glucocorticoid-induced tumour necrosis factor receptor (GITR) expressing cells, CD4+CD25+Foxp3+ regulatory T (Treg) cells, Th17 cells, Th1 cytokines, and inflammatory mediator gene expression. Wound size was recorded on every third day and after 14 days of treatment, the heparinised whole blood and the wound tissue of all the groups was collected and tested.', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755973 {'content.chapter.sentpositive': 'Diabetes can hinder the normal wound healing process by inducing long-term inflammation which can lead to delayed maturation of granulation tissues, reduced wound parallel tension and inhibition of angiogenesis [1]. Delayed wound healing constitutes one of the most serious diabetes-associated complications.', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755971 {'content.chapter.sentpositive': 'Wound size was recorded on every third day and after 14 days of treatment, the heparinised whole blood and the wound tissue of all the groups was collected and tested. In this study, five groups of Swiss albino mice were used (10 mice per group): group 1, the non-diabetic (normal control; N+M); group 2, wound in non-diabetic mice (N+W); group 3, wound in diabetic mice (D+W); group 4, Limonene 50mg/kg treated wounds in diabetic mice (D+W+L50); group 5, Limonene 100mg/kg treated wounds in diabetic mice.', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755972 {'content.chapter.sentpositive': 'Delayed wound healing constitutes one of the most serious diabetes-associated complications. D-limonene, one of the major constituent in citrus essential oils is considered to have antioxidant, hypoglycemic and anti-inflammatory activities [2].', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755977 {'content.chapter.sentpositive': 'This might contribute to its enhanced wound healing. Limonene also significantly up regulated the number of Tregs or it also induced Th17/Treg balance and modulated various pro-inflammatory and anti-inflammatory cytokines and the gene expression of their mediators that mediate inflammation.', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n",
      "PMC_40755978 {'content.chapter.sentpositive': 'Furthermore, histopathological examination showed complete re-epithelisation, decreased inflammatory cells and presence of granulation tissue in the limonene treated mice. This might contribute to its enhanced wound healing.', 'title': 'Enhanced wound healing by topical administration of d-limonene in alloxan induced diabetic mice through reduction of pro-inflammatory markers and chemokine expression', 'paper_id': 'PMC_4075597'}\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index = \"twosent\", body = {\"query\": {\"match\": {\"paper_id\" : \"PMC_4075597\"}}}, size = 200)\n",
    "\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_id'], hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 377 Hits:\n",
      "PMC_1851393 Risk of second primary cancer in men with breast cancer 5.460385\n",
      "PMC_4579663 An ecological measure of immune-cancer colocalization as a prognostic factor for breast cancer 4.976323\n",
      "PMC_340959 A New Breast Cancer Model 4.824152\n",
      "PMC_4940926 Systemic therapy for breast cancer and risk of subsequent contralateral breast cancer in the WECARE Study 4.7360334\n",
      "PMC_3720249 Vav Proteins' Role in Skin Cancer 4.702413\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index = \"ir\", body = {\"query\": {\"match\": {\"title\" : \"cancer\"}}}, size = 5)\n",
    "\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit[\"_id\"], hit['_source']['title'], hit['_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2202 Hits:\n",
      "PMC_4122943 Evolutionary Dynamics of the Mitochondrial Genome in the Evaniomorpha (Hymenoptera)—A Group with an Intermediate Rate of Gene Rearrangement 8.314648\n",
      "PMC_4122925 Pangenome Evidence for Extensive Interdomain Horizontal Transfer Affecting Lineage Core and Shell Genes in Uncultured Planktonic Thaumarchaeota and Euryarchaeota 8.314648\n",
      "PMC_4558866 Chemoreceptor Evolution in Hymenoptera and Its Implications for the Evolution of Eusociality 8.314648\n",
      "PMC_4494066 Distinctive Genome Reduction Rates Revealed by Genomic Analyses of Two  Coxiella- Like Endosymbionts in Ticks 8.314648\n",
      "PMC_4231633 Three Classes of Plasmid (47–63 kb) Carry the Type B Neurotoxin Gene Cluster of Group II  Clostridium botulinum 8.314648\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index = \"ir\", body = {\"query\": {\"match\": {\"publication\" : \"Genome Biology and Evolution\"}}}, size = 5)\n",
    "\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit[\"_id\"], hit['_source']['title'], hit['_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 202 Hits:\n",
      "PMC_2211537 The Genetic Structure of Pacific Islanders\n",
      "PMC_4858160 Exploiting Genetic Interference for Antiviral Therapy\n",
      "PMC_3185286 Find the weakest link. A comparison between demographic, genetic and demo-genetic metapopulation extinction times\n",
      "conf_icse_WeimerNGF09 Automatically finding patches using genetic programming.\n",
      "PMC_3341339 A Genetic Basis for Mechanosensory Traits in Humans\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index = \"ir\", body = {\"query\": {\"match\": {\"title\" : \"genetic\"}}}, size = 5)\n",
    "\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_id'], hit['_source']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8003 Hits:\n",
      "PMC_2408596 Gene Structure Evolution of the Na + -Ca 2+  Exchanger ( NCX ) Family\n",
      "____________________________________________________________________________________________________\n",
      "PMC_4712596 Genomic and metagenomic analysis of microbes in a soil environment affected by the 2011 Great East Japan Earthquake tsunami\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_BreckBFHLM99 A Sys Called Qanda.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_Westerveld06 Correlating Topic Rankings and Person Rankings to Find Experts.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_MoulahiTMY14 IRIT at TREC 2014 Contextual Suggestion Track.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_SutcliffeGMW03 Question Answering using the DLT System at TREC 2003.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_RodeH04 Conceptual Language Models for Context-Aware Text Retrieval.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_BrownDH03 IBM Research and the University of Colorado - TREC 2003 Genomics Track.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_KimYC12 Overcoming Vocabulary Limitations in Twitter Microblogs.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_BuccioMN10 Evaluation of a Methodology for Modeling Term Relationship through Geometry: Experiments at TREC 2010 Relevance Feedback Track.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_ChangXB03 TREC 2003 Question Answering Track at CAS-ICT.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_SinghalABCHP99 AT&T at TREC-8.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_VtyurinaDSC15 WaterlooClarke: TREC 2015 LiveQA Track.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_WuZDLS03 Questioning Answering By Pattern Matching, Web-Proofing, Semantic Form Proofing.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_Zimmermann11 Chemical Structure Reconstruction with chemoCR.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_AvulaOA13 A Nearest Neighbor Approach to Contextual Suggestion.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_CaporasoBCJPH05 Concept Recognition and the TREC Genomics Tasks.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_Mishne06 Multiple Ranking Strategies for Opinion Retrieval in Blogs - The University of Amsterdam at the 2006 TREC Blog Track.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_SutcliffeWGM06 Question Answering Using the DLT System at TREC 2006.\n",
      "____________________________________________________________________________________________________\n",
      "conf_trec_DayanikNO03 Partioning a Graph of Sequences, Structures and Abstracts for Information Retrieval.\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index = \"ir\", body = {\"query\": {'query_string' : {\n",
    "                                        'query': '*onstruct*',\n",
    "                                        'fields': ['text']}}}, size = 20)\n",
    "\n",
    "print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_id'], hit['_source']['title'])\n",
    "    print('_'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5 Doc2vec Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import config as cfg\n",
    "\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "client = MongoClient('localhost:' + str(cfg.mongoDB_Port))\n",
    "pub = client.pub.publications\n",
    "db=client.pub\n",
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}],timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "\n",
    "# es.cluster.health(wait_for_status='yellow', request_timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = ' An important difference between citing and co-citation networks, however, is size. Since papers in the biomedical sciences have a median of 30 articles in their reference lists, each citation event can be expected to add multiple papers to an article’s co-citation network (Fig 1D) but only one to its citing network. The latter are therefore highly vulnerable to finite number effects; in other words, for an article of interest with few citations, small changes in the citing network would have a disproportionate effect on how that article’s field was defined. We therefore chose to pursue co-citation networks as a way to describe an individual paper’s field.Having chosen our comparison group, we looked for a way to test how accurately co-citation networks represent an article’s field. One way to characterize groups of documents is to cluster them based on the frequency at which specific terms appear in a particular document relative to the frequency at which they appear in the entire corpus, a method known as term frequency–inverse document frequency (TF-IDF) . This is not a perfect approach, as it is possible to use entirely different words to describe similar concepts, but positive matches can be taken as a strong indication of similarity. Frequency of word occurrence can be converted into vectors so that the cosine of the angle between two vectors is a measurement of how alike the two documents are. To evaluate co-citation networks relative to journal of publication, which is often used as a proxy for field, we selected all papers published from 2002 to 2011 in each of six different journals that received exactly five citations during that same time frame.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = 'exposed to increasing volumes of mcf7 and mdamb231 breast cancer cell cm or incubated with control volumes of concentrated serumfree media for 48 h after the 48 h incubation time cells and debris were removed from the thp1 supernatant by centrifugation following incubation the recovered cell number was determined and cell viability established using trypan blue exclusion under the conditions in this study the treatment of thp1 cells with cm did not reduce the viability of the thp1 cellsthe cm protein levels were quantified using a protein assay biorad hercules ca usa and the results were compared with a standard curve of bsa concentrations the protein concentrations were used to normalize the amount of cm loaded onto the gel thus the total protein loaded was equivalent in each lane loading buffer 5 wv sds 0225 m triscl ph 68 50 wv glycerol 005 wv bromophenol blue 025 m dithiothreitol was added to the cm and the mixture was denatured by boiling for 5 minutes samples were loaded onto a 10 sds polyacrylamide gel with 10 μl of a widerange colored protein molecular weight marker invitrogen carlsbad ca usa also loaded onto the gel the proteins were subsequently transferred from the gel onto a nitrocellulose membrane amersham biosciences piscataway nj usa the membrane was incubated with mouse monoclonal antimmp2 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "papernames=[]\n",
    "###############################\n",
    "file = open('data/allcorpus_papers.txt', 'r')\n",
    "text = file.read()\n",
    "\n",
    "sentences = tokenize.sent_tokenize(text)\n",
    "count = 0\n",
    "docLabels = []\n",
    "actions = []\n",
    "\n",
    "for i, sent in enumerate(sentences):\n",
    "    try:\n",
    "        neighbors = sentences[i + 1]\n",
    "        neighbor_count = count + 1\n",
    "        \n",
    "    except:\n",
    "        neighbors = sentences[i - 1]\n",
    "        neighbor_count = count - 1\n",
    "\n",
    "    docLabels.append(count)\n",
    "\n",
    "    actions.append({\n",
    "       \"_index\": \"devtwosentnew\",\n",
    "       \"_type\": \"devtwosentnorulesnew\",\n",
    "       \"_id\":count,\n",
    "\n",
    "       \"_source\" : {\n",
    "           \"content.chapter.sentpositive\" : sent,\n",
    "           \"content.chapter.sentnegtive\": neighbors,\n",
    "           \"neighborcount\":neighbor_count\n",
    "       }})\n",
    "    count = count + 1\n",
    "\n",
    "print(len(sentences))\n",
    "print(len(docLabels))\n",
    "\n",
    "res = helpers.bulk(es, actions)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5 Preparing doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import math\n",
    "import nltk\n",
    "import string\n",
    "import config as cfg\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "###############################\n",
    "\n",
    "client = MongoClient('localhost:' + str(cfg.mongoDB_Port))\n",
    "db = client.pub\n",
    "pub = client.pub.publications\n",
    "es = Elasticsearch(\n",
    "    [{'host': 'localhost', 'port': 9200}], timeout=30, max_retries=10, retry_on_timeout=True\n",
    ")\n",
    "es.cluster.health(wait_for_status='yellow', request_timeout=1)\n",
    "\n",
    "list_of_pubs=[]\n",
    "\n",
    "def returnnames(mongo_string_search, db):\n",
    "    # mongo_string_search = {\"dblpkey\": \"{}\".format(dblkey)}\n",
    "    results = db.publications.find(mongo_string_search)\n",
    "    chapters = list()\n",
    "    chapter_nums = list()\n",
    "    list_of_docs = list()\n",
    "    # list_of_abstracts = list()\n",
    "    merged_chapters = list()\n",
    "    my_dict = {\n",
    "        \"_id\": \"\",\n",
    "\n",
    "    }\n",
    "    for i, r in enumerate(results):\n",
    "        # try:\n",
    "        # list_of_sections = list()\n",
    "        my_dict['_id'] = r['_id']\n",
    "        list_of_docs.append((my_dict))\n",
    "\n",
    "        my_dict = {\n",
    "            \"_id\": \"\",\n",
    "\n",
    "        }\n",
    "\n",
    "    return list_of_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filter_conference = [\"WWW\", \"ICSE\", \"VLDB\", \"PVLDB\", \"JCDL\", \"TREC\",  \"SIGIR\", \"ICWSM\", \"ECDL\", \"ESWC\"]\n",
    "\n",
    "for booktitle in filter_conference:\n",
    "    mongo_string_search = {'$and': [{'booktitle': booktitle}, {'content.fulltext': {'$exists': True}}]}\n",
    "    list_of_pubs.append(returnnames(mongo_string_search, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mongo_string_search = {'$and': [{'domain': 'Biomedical'}, {'content.fulltext': {'$exists': True}}]}\n",
    "list_of_pubs.append(returnnames(mongo_string_search, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "papersText = []\n",
    "\n",
    "for pubs in list_of_pubs:\n",
    "\n",
    "    for cur in pubs:\n",
    "\n",
    "        query = {\"query\":\n",
    "            {\"match\": {\n",
    "                \"_id\": {\n",
    "                    \"query\": cur['_id'],\n",
    "                    \"operator\": \"and\"\n",
    "                }\n",
    "            }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        res = es.search(index = \"ir\", body = query, size = 200)\n",
    "\n",
    "        for doc in res['hits']['hits']:\n",
    "            # sentence = doc[\"_source\"][\"text\"].replace(',', ' ')\n",
    "            fulltext = doc[\"_source\"][\"text\"]\n",
    "\n",
    "            fulltext = fulltext.translate(str.maketrans('', '', string.punctuation))\n",
    "            \n",
    "            papersText.append(fulltext.lower())\n",
    "            \n",
    "papersText = \" \".join(papersText)\n",
    "\n",
    "f1 = open(\"data/word2vecData.txt\", \"w\")\n",
    "f1.write(papersText)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
